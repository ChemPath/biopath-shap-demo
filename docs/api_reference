# BioPath API Reference

**Version**: 1.0.0-beta (Proof of Concept)  
**Last Updated**: July 2025  
**Status**: Development Phase - Framework Design

## Overview

BioPath provides a comprehensive API framework for cultural bias-corrected therapeutic validation. This reference documents the planned API design, core classes, and methods for integrating SHAP-based bias detection into therapeutic research workflows.

**Note**: BioPath is currently in proof-of-concept development. This documentation describes the planned API design and may change as development progresses.

## Table of Contents

1. [Installation & Setup](#installation--setup)
2. [Core Classes](#core-classes)
3. [Cultural Bias Detection](#cultural-bias-detection)
4. [Therapeutic Validation](#therapeutic-validation)
5. [EquiPath Integration](#equipath-integration)
6. [Deployment Modes](#deployment-modes)
7. [Research Workflows](#research-workflows)
8. [Error Handling](#error-handling)
9. [Performance Benchmarks](#performance-benchmarks)

## Installation & Setup

### Requirements

```python
# Python 3.8+
pip install biopath-shap>=1.0.0-beta
pip install shap>=0.41.0
pip install scikit-learn>=1.0.0
pip install pandas>=1.3.0
pip install numpy>=1.21.0
```

### Basic Configuration

```python
from biopath import TherapeuticValidator, CulturalBiasDetector
from biopath.equipath import CompensationTracker

# Initialize BioPath framework
validator = TherapeuticValidator(
    bias_threshold=0.30,  # 30% traditional knowledge threshold
    compensation_model="equitable_sharing",
    validation_mode="academic_research"
)

# Configure cultural bias detection
bias_detector = CulturalBiasDetector(
    shap_explainer="tree",
    cultural_weight_threshold=0.25,
    traditional_knowledge_sources=["ethnobotanical_db", "indigenous_records"]
)
```

## Core Classes

### TherapeuticValidator

Primary class for validating therapeutic compounds with cultural bias correction.

```python
class TherapeuticValidator:
    """
    Validates therapeutic compounds using SHAP-based cultural bias detection.
    
    This class implements the core BioPath methodology for ensuring equitable
    representation of traditional knowledge in therapeutic validation.
    """
    
    def __init__(self, bias_threshold: float = 0.30, 
                 compensation_model: str = "equitable_sharing",
                 validation_mode: str = "academic_research"):
        """
        Initialize therapeutic validator.
        
        Args:
            bias_threshold: Maximum acceptable cultural bias (0.0-1.0)
            compensation_model: EquiPath compensation strategy
            validation_mode: Research context ("academic_research", "commercial", "nonprofit")
        """
        
    def validate_compound(self, compound_data: dict, 
                         traditional_sources: list) -> ValidationResult:
        """
        Validate therapeutic compound with bias correction.
        
        Args:
            compound_data: Chemical and biological property data
            traditional_sources: List of traditional knowledge sources
            
        Returns:
            ValidationResult: Comprehensive validation with bias metrics
            
        Example:
            result = validator.validate_compound(
                compound_data={
                    "smiles": "CC(C)CC1=CC=C(C=C1)C(C)C(=O)O",
                    "bioactivity": {"ic50": 2.3, "selectivity": 0.89},
                    "molecular_weight": 206.28
                },
                traditional_sources=[
                    {"culture": "Quechua", "plant": "Cinchona officinalis", 
                     "preparation": "bark_extract", "confidence": 0.92}
                ]
            )
        """
        
    def batch_validate(self, compounds: list, 
                      sources_mapping: dict) -> BatchValidationResult:
        """
        Validate multiple compounds efficiently.
        
        Args:
            compounds: List of compound data dictionaries
            sources_mapping: Mapping of compound IDs to traditional sources
            
        Returns:
            BatchValidationResult: Results for all compounds with summary statistics
        """

    def generate_bias_report(self, validation_results: list) -> BiasReport:
        """
        Generate comprehensive bias analysis report.
        
        Args:
            validation_results: List of ValidationResult objects
            
        Returns:
            BiasReport: Statistical analysis of cultural representation bias
        """
```

### CulturalBiasDetector

SHAP-based bias detection for cultural representation analysis.

```python
class CulturalBiasDetector:
    """
    Detects and quantifies cultural bias in therapeutic validation datasets.
    
    Uses SHAP (SHapley Additive exPlanations) to identify when traditional
    knowledge is under-represented or over-weighted in validation models.
    """
    
    def analyze_dataset_bias(self, dataset: pd.DataFrame, 
                           cultural_features: list) -> BiasAnalysis:
        """
        Analyze cultural representation bias in research dataset.
        
        Args:
            dataset: Research dataset with cultural and chemical features
            cultural_features: List of column names representing cultural data
            
        Returns:
            BiasAnalysis: Detailed bias metrics and recommendations
            
        Example:
            bias_analysis = detector.analyze_dataset_bias(
                dataset=research_df,
                cultural_features=["traditional_use", "cultural_origin", 
                                 "indigenous_preparation", "ethnobotanical_reference"]
            )
        """
        
    def explain_prediction_bias(self, model, compound_data: dict, 
                               cultural_context: dict) -> ExplanationResult:
        """
        Explain prediction bias for individual compound.
        
        Args:
            model: Trained therapeutic validation model
            compound_data: Compound features and properties
            cultural_context: Traditional knowledge context
            
        Returns:
            ExplanationResult: SHAP values and bias explanation
        """
        
    def recommend_bias_correction(self, bias_analysis: BiasAnalysis) -> CorrectionPlan:
        """
        Recommend specific actions to correct identified bias.
        
        Args:
            bias_analysis: Results from analyze_dataset_bias()
            
        Returns:
            CorrectionPlan: Actionable steps to reduce cultural bias
        """
```

### ValidationResult

Comprehensive validation result with bias metrics.

```python
class ValidationResult:
    """
    Contains validation results with cultural bias analysis.
    """
    
    def __init__(self):
        self.compound_id: str
        self.therapeutic_score: float  # 0.0-1.0 efficacy prediction
        self.cultural_bias_score: float  # 0.0-1.0 bias level
        self.traditional_weight: float  # Traditional knowledge contribution
        self.shap_values: dict  # Feature importance breakdown
        self.bias_status: str  # "SAFE", "CAUTION", "BIASED"
        self.compensation_due: float  # EquiPath compensation amount
        self.validation_confidence: float  # Statistical confidence
        self.recommendations: list  # Actionable next steps
        
    def is_bias_acceptable(self, threshold: float = 0.30) -> bool:
        """Check if bias level is within acceptable limits."""
        
    def get_cultural_representation_summary(self) -> dict:
        """Get summary of traditional knowledge representation."""
        
    def export_for_publication(self) -> dict:
        """Export results in academic publication format."""
```

## Cultural Bias Detection

### SHAP Integration

BioPath uses SHAP (SHapley Additive exPlanations) to identify when therapeutic validation models unfairly under-represent or over-weight traditional knowledge sources.

```python
# Example: Detecting bias in compound validation
from biopath.shap_integration import SHAPAnalyzer

analyzer = SHAPAnalyzer(
    model_type="therapeutic_validation",
    explainer_type="tree",  # or "linear", "deep", "kernel"
    cultural_features=["traditional_use_frequency", "cultural_origin", 
                      "ethnobotanical_reference_count"]
)

# Analyze bias for specific prediction
bias_explanation = analyzer.explain_bias(
    model=validation_model,
    sample_data=compound_features,
    cultural_context={
        "primary_culture": "Amazonian Indigenous",
        "traditional_preparation": "ayahuasca_component",
        "documentation_level": "extensive"
    }
)

print(f"Cultural bias level: {bias_explanation.bias_score:.3f}")
print(f"Traditional knowledge weight: {bias_explanation.traditional_weight:.3f}")
print(f"Bias status: {bias_explanation.status}")
```

### Bias Threshold Management

```python
# Configure bias detection thresholds
bias_config = {
    "cultural_weight_minimum": 0.15,  # Min traditional knowledge contribution
    "cultural_weight_maximum": 0.60,  # Max to avoid over-reliance
    "bias_alert_threshold": 0.25,     # Trigger bias warning
    "bias_rejection_threshold": 0.40  # Reject validation if exceeded
}

validator.update_bias_thresholds(bias_config)

# Validate with custom thresholds
result = validator.validate_compound(
    compound_data=sample_compound,
    traditional_sources=traditional_data,
    custom_threshold=0.20  # Stricter bias tolerance
)
```

## Therapeutic Validation

### Standard Validation Workflow

```python
# Complete therapeutic validation example
from biopath import TherapeuticValidator
from biopath.data import TraditionalKnowledgeDB

# Initialize components
validator = TherapeuticValidator(bias_threshold=0.30)
tk_database = TraditionalKnowledgeDB(ethical_clearance=True)

# Load compound data
compound = {
    "compound_id": "BPT_001",
    "smiles": "CC1=CC=C(C=C1)C(=O)NC2=CC=C(C=C2)S(=O)(=O)N",
    "molecular_weight": 290.34,
    "bioactivity": {
        "target_enzyme": "COX-2",
        "ic50_nM": 150,
        "selectivity_ratio": 12.3
    },
    "chemical_properties": {
        "logP": 2.1,
        "hbd": 2,
        "hba": 4,
        "psa": 83.55
    }
}

# Retrieve traditional knowledge
traditional_sources = tk_database.query_compound_sources(
    compound_id="BPT_001",
    include_cultures=["Quechua", "Shipibo", "Ashuar"],
    min_confidence=0.80
)

# Perform validation
validation_result = validator.validate_compound(
    compound_data=compound,
    traditional_sources=traditional_sources
)

# Check results
if validation_result.is_bias_acceptable():
    print(f"‚úÖ Validation passed - Therapeutic score: {validation_result.therapeutic_score:.3f}")
    print(f"üìä Traditional knowledge weight: {validation_result.traditional_weight:.3f}")
    print(f"‚öñÔ∏è Cultural bias level: {validation_result.cultural_bias_score:.3f}")
    
    # Process EquiPath compensation
    compensation = validation_result.compensation_due
    print(f"üí∞ Compensation due: ${compensation:.2f}")
else:
    print(f"‚ùå Validation failed - Bias level too high: {validation_result.cultural_bias_score:.3f}")
    print("üìã Recommended corrections:")
    for rec in validation_result.recommendations:
        print(f"  ‚Ä¢ {rec}")
```

### Batch Processing for Research Studies

```python
# Process multiple compounds for research study
from biopath.batch import BatchProcessor

processor = BatchProcessor(
    validator=validator,
    parallel_workers=4,
    progress_tracking=True
)

# Load research dataset
compounds_df = pd.read_csv("research_compounds.csv")
traditional_mapping = tk_database.batch_query(compounds_df.compound_id.tolist())

# Batch validation
batch_results = processor.validate_batch(
    compounds=compounds_df.to_dict('records'),
    traditional_sources=traditional_mapping,
    export_format="academic_report"
)

# Generate summary statistics
summary = batch_results.generate_summary()
print(f"Compounds validated: {summary.total_compounds}")
print(f"Average bias score: {summary.mean_bias_score:.3f}")
print(f"Compounds requiring bias correction: {summary.high_bias_count}")
print(f"Total compensation due: ${summary.total_compensation:.2f}")
```

## EquiPath Integration

### Compensation Tracking

```python
from biopath.equipath import CompensationTracker, CommunityRegistry

# Initialize compensation system
compensation_tracker = CompensationTracker(
    blockchain_network="ethereum_testnet",  # Development mode
    transparency_level="full_public",
    payment_schedule="quarterly"
)

# Register traditional knowledge contributors
community_registry = CommunityRegistry()
community_registry.register_contributor(
    culture_name="Quechua Nation",
    contact_representative="Dr. Maria Gonzalez",
    preferred_compensation="community_development_fund",
    verification_status="academic_partnership"
)

# Process compensation from validation
for result in validation_results:
    if result.compensation_due > 0:
        compensation_tracker.record_compensation(
            compound_id=result.compound_id,
            amount=result.compensation_due,
            traditional_sources=result.traditional_sources,
            researcher_institution="University Research Lab"
        )

# Generate transparency report
compensation_report = compensation_tracker.generate_quarterly_report()
print(f"Total compensation distributed: ${compensation_report.total_amount}")
print(f"Communities compensated: {compensation_report.community_count}")
```

## Deployment Modes

### Academic Research Mode

```python
# Configure for academic research (non-commercial)
academic_validator = TherapeuticValidator(
    validation_mode="academic_research",
    bias_threshold=0.25,  # Stricter for research
    compensation_model="acknowledgment_plus_micro_payments",
    ethical_review_required=True
)

# Research-specific features
academic_validator.enable_publication_export()
academic_validator.set_peer_review_mode(True)
academic_validator.configure_institutional_compliance(
    institution="University Research Lab",
    irb_protocol_number="IRB-2025-0789"
)
```

### Commercial Development Mode

```python
# Configure for commercial therapeutic development
commercial_validator = TherapeuticValidator(
    validation_mode="commercial",
    bias_threshold=0.30,
    compensation_model="revenue_sharing",
    legal_compliance="full_pharma"
)

# Commercial-specific features
commercial_validator.enable_patent_screening()
commercial_validator.set_regulatory_reporting(
    agencies=["FDA", "EMA"],
    development_phase="preclinical"
)
```

### Nonprofit/Educational Mode

```python
# Configure for nonprofit organizations
nonprofit_validator = TherapeuticValidator(
    validation_mode="nonprofit",
    bias_threshold=0.20,  # Most strict
    compensation_model="capacity_building",
    mission_alignment_required=True
)
```

## Research Workflows

### Complete Research Pipeline

```python
# Full research workflow example
from biopath.workflows import ResearchPipeline

pipeline = ResearchPipeline(
    name="Amazonian_Therapeutics_Study_2025",
    principal_investigator="Dr. Research Lead",
    institution="University Research Lab",
    ethical_clearance="IRB-2025-0789"
)

# Step 1: Dataset preparation with bias checking
dataset = pipeline.prepare_dataset(
    compound_sources=["chemical_databases", "traditional_knowledge_db"],
    cultural_sources=["ethnobotanical_records", "indigenous_interviews"],
    bias_preprocessing=True
)

# Step 2: Model training with bias monitoring
model = pipeline.train_validation_model(
    dataset=dataset,
    algorithm="gradient_boosting",
    bias_monitoring=True,
    cross_validation_folds=5
)

# Step 3: Validation with bias correction
results = pipeline.validate_compounds(
    test_compounds=test_set,
    model=model,
    bias_correction_enabled=True
)

# Step 4: Generate academic report
academic_report = pipeline.generate_academic_report(
    results=results,
    include_methodology=True,
    include_ethics_statement=True,
    include_compensation_transparency=True
)

# Export for publication
academic_report.export_latex("manuscript_results.tex")
academic_report.export_csv("supplementary_data.csv")
```

### Integration with Existing Research Tools

```python
# Integration with popular research frameworks
from biopath.integrations import RDKitIntegration, SciKitLearnIntegration

# RDKit molecular descriptors with bias checking
rdkit_integration = RDKitIntegration(validator)
descriptors_with_bias_check = rdkit_integration.calculate_descriptors(
    molecules=compound_smiles_list,
    include_bias_analysis=True
)

# Scikit-learn model validation with cultural bias metrics
sklearn_integration = SciKitLearnIntegration(validator)
cv_results = sklearn_integration.cross_validate_with_bias_check(
    model=therapeutic_model,
    X=features,
    y=targets,
    cultural_features=cultural_feature_names,
    cv=5
)
```

## Error Handling

### Common Error Types

```python
from biopath.exceptions import (
    CulturalBiasError,
    TraditionalKnowledgeError,
    ValidationError,
    CompensationError
)

try:
    result = validator.validate_compound(compound_data, traditional_sources)
    
except CulturalBiasError as e:
    print(f"Cultural bias detected: {e.bias_level:.3f} > {e.threshold:.3f}")
    print(f"Recommended action: {e.correction_suggestion}")
    
except TraditionalKnowledgeError as e:
    print(f"Traditional knowledge issue: {e.message}")
    print(f"Missing sources: {e.missing_sources}")
    
except ValidationError as e:
    print(f"Validation failed: {e.reason}")
    print(f"Technical details: {e.technical_details}")
    
except CompensationError as e:
    print(f"Compensation calculation failed: {e.message}")
    print(f"Manual review required: {e.manual_review_needed}")
```

### Graceful Degradation

```python
# Handle cases where traditional knowledge is limited
from biopath.fallbacks import LimitedKnowledgeHandler

fallback_handler = LimitedKnowledgeHandler(
    minimum_confidence=0.60,
    alternative_databases=["chemical_similarity", "literature_mining"],
    bias_adjustment_method="conservative"
)

# Attempt validation with fallback
try:
    result = validator.validate_compound(compound_data, traditional_sources)
except TraditionalKnowledgeError:
    # Use fallback method with adjusted bias thresholds
    fallback_result = fallback_handler.validate_with_limited_knowledge(
        compound_data=compound_data,
        available_sources=partial_traditional_sources,
        confidence_adjustment=0.15
    )
    print(f"‚ö†Ô∏è Limited traditional knowledge available")
    print(f"Fallback validation confidence: {fallback_result.confidence:.3f}")
```

## Performance Benchmarks

### Validation Performance

Based on proof-of-concept testing:

```python
# Performance metrics (development benchmarks)
performance_metrics = {
    "accuracy_improvement": 0.447,  # 44.7% improvement over baseline
    "bias_detection_accuracy": 0.892,  # 89.2% accurate bias detection
    "cultural_representation_increase": 0.356,  # 35.6% better representation
    "false_positive_reduction": 0.234,  # 23.4% fewer false positives
    "processing_time_per_compound": "0.45 seconds",
    "batch_processing_throughput": "2,200 compounds/hour",
    "memory_usage": "~150MB per 1,000 compounds"
}

# Access performance data
from biopath.benchmarks import PerformanceBenchmarks

benchmarks = PerformanceBenchmarks()
current_performance = benchmarks.run_validation_benchmark(
    test_compounds=benchmark_dataset,
    iterations=100
)

print(f"Average accuracy: {current_performance.accuracy:.3f}")
print(f"Bias detection rate: {current_performance.bias_detection:.3f}")
print(f"Processing speed: {current_performance.compounds_per_second:.1f}/sec")
```

### Scalability Testing

```python
# Test scalability for large research studies
from biopath.testing import ScalabilityTester

scalability = ScalabilityTester()
scale_results = scalability.test_batch_sizes(
    batch_sizes=[100, 500, 1000, 5000, 10000],
    test_iterations=10
)

for batch_size, metrics in scale_results.items():
    print(f"Batch size {batch_size}: {metrics.avg_time:.2f}s, "
          f"{metrics.memory_usage:.1f}MB, "
          f"{metrics.accuracy:.3f} accuracy")
```

## API Versioning & Updates

### Version Management

```python
import biopath

# Check current version
print(f"BioPath version: {biopath.__version__}")
print(f"API compatibility: {biopath.api_version}")

# Check for updates (development feature)
update_checker = biopath.UpdateChecker()
if update_checker.new_version_available():
    print(f"New version available: {update_checker.latest_version}")
    print(f"Release notes: {update_checker.get_release_notes()}")
```

### Backward Compatibility

```python
# Handle version compatibility
from biopath.compatibility import VersionManager

version_manager = VersionManager()

# Automatically handle API changes
compatible_validator = version_manager.get_compatible_validator(
    target_api_version="1.0.0",
    current_data_format="legacy_validation_format"
)
```

## Development Status & Roadmap

### Current Implementation Status

- ‚úÖ **Core API Design**: Framework architecture completed
- ‚úÖ **SHAP Integration**: Bias detection methodology designed
- ‚úÖ **EquiPath Framework**: Compensation system outlined
- üöß **Traditional Knowledge Database**: In development
- üöß **Model Training Pipeline**: Proof-of-concept stage
- üìã **Clinical Integration**: Planned for future development
- üìã **Regulatory Compliance**: Requirements analysis phase

### Research Partnerships

BioPath is actively seeking academic partnerships for:
- Validation of bias detection algorithms
- Traditional knowledge database development
- Clinical application research
- Ethical framework refinement

**Contact**: For research collaborations, contact [research@omnipath.ai](mailto:research@omnipath.ai)

---

**Disclaimer**: BioPath is currently in proof-of-concept development. This API documentation represents the planned framework design and may change significantly during development. Performance benchmarks are based on limited testing and should not be considered production-ready metrics.

**Ethics Statement**: BioPath is committed to ethical sourcing of traditional knowledge, transparent compensation mechanisms, and respectful collaboration with indigenous communities. All traditional knowledge integration follows established ethical guidelines and requires appropriate community consent.

**License**: BioPath API framework is developed under Apache 2.0 license for academic research use. Commercial licensing available through OmniPath partnership agreements.
